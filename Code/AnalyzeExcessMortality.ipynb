{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis\n",
    "This notebooks carries out the main analysis of excess mortality\n",
    "\n",
    "The notebooks goes through each county-file (for each possible period), and determines a mortality baseline using the functions in the ExcessMortalityFunctions repository.\n",
    "\n",
    "The preliminary resuls are saved to files outside the repository for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saveFigures is set to: True\n",
      "Done loading packages\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "# Load style\n",
    "plt.style.use('PlotStyle.mplstyle')\n",
    "import matplotlib.colors as colors\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.Dark2.colors)\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "# Load functions\n",
    "import sys\n",
    "sys.path.append(\"../../ExcessMortality\")\n",
    "import ExcessMortalityFunctions as emf\n",
    "import AdditionalFunctions as ps\n",
    "\n",
    "\n",
    "saveFigures = True\n",
    "# saveFigures = False\n",
    "print('saveFigures is set to: '+str(saveFigures))\n",
    "print('Done loading packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "pathData = '../Data/MortalityCollections/'\n",
    "# pathToSaveResultsIn = '../../AnalysisResults' # NOTE: Outside repo! This is done to save space within repo. In the final part of the analysis, everything is put together in a single file\n",
    "pathToSaveResultsIn = '../Data/AnalysisResults' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRel = pd.read_csv('../SupplementaryTable_RelationalTable_ParishCounty.csv')\n",
    "dfRel['StartDate'] = pd.to_datetime(dfRel.StartDate)\n",
    "dfRel['EndDate'] = pd.to_datetime(dfRel.EndDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfRel = dfRel.rename(columns={\n",
    "#     'fra':'StartDate',\n",
    "#     'til':'EndDate',\n",
    "# })\n",
    "\n",
    "# dfRel.to_csv('../SupplementaryTable_RelationalTable_ParishCounty.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# Only consider counties that exists after 1810 \n",
    "# (A large restructuring was done between 1800 and 1810)\n",
    "# print(dfRel.AmtID.unique())\n",
    "print(len(dfRel.AmtID.unique()))\n",
    "allAmtIDs = dfRel[dfRel.EndDate > np.datetime64('1810-01-01')].AmtID.unique()\n",
    "# print(allAmtIDs)\n",
    "print(len(allAmtIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags and analysis parameters\n",
    "numYears = 6 # Number of years on both sides of date to use for baseline calculations \n",
    "# numYears = 12 # Number of years on both sides of date to use for baseline calculations \n",
    "numYearsTot = (numYears*2) # The \"name\" of the baseline (i.e. +/- 5 years is a 10-year baseline, +/- 12 is a 24 year baseline)\n",
    "thresholdExcess = 3 # Threshold (in terms of Z-scores) for identifying a day as having increased excess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pathToSaveResultsInUpper = pathToSaveResultsIn + f'_Years{numYears}_Threshold{thresholdExcess}/'\n",
    "\n",
    "# Create directory if it doesn't already exist\n",
    "try:\n",
    "    os.mkdir(pathToSaveResultsInUpper)\n",
    "except:\n",
    "    2+2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agegroups to analyze\n",
    "ageGroups = [\n",
    "    ['Total'],\n",
    "    ['Stillborn','0'],\n",
    "    ['1-4','5-9', '10-14'],\n",
    "    ['15-19', '20-24', '25-29', '30-34', '35-39'],\n",
    "    ['40-44', '45-49', '50-54', '55-59'],\n",
    "    ['60-64', '65-69', '70-74', '75-79', '80+']\n",
    "]\n",
    "\n",
    "# And the names to use for directories and filenames\n",
    "ageGroupNames = [\n",
    "    'Total',\n",
    "    'Infants_stillborn',\n",
    "    '1-14',\n",
    "    '15-39',\n",
    "    '40-59',\n",
    "    '60+'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for summing columns\n",
    "def sumColumns(curdf,columnsToUse=['Total']):\n",
    "    # Returns the sum of the columns specified\n",
    "    return curdf[columnsToUse].sum(axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [19:16<00:00, 42.85s/it, Amt=Nordborg Amt, Period=2, Total periods=2, Start=1867-09-22, End=1915-01-01, Agegroup=60+]                   \n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "##### Run analysis for each of the agegroups #####\n",
    "############ Takes about half an hour ############ \n",
    "##################################################\n",
    "\n",
    "# Prepare progressbar and go through each county\n",
    "pbar = tqdm(allAmtIDs)\n",
    "for curAmtID in pbar:\n",
    "\n",
    "    # Get county name, data and periods\n",
    "    curAmtName = ps.getAmtName(curAmtID)\n",
    "    alldfs,allStarts,allEnds = ps.getAmtCollections(curAmtID)\n",
    "\n",
    "    # Go through each possible period\n",
    "    for i in range(len(allStarts)):\n",
    "\n",
    "        # Get the dataframe, start date and end date\n",
    "        curdf = alldfs[i].copy()\n",
    "        curStart = allStarts[i]\n",
    "        curEnd = allEnds[i]\n",
    "\n",
    "        # Ensure date is datetime\n",
    "        curdf['Date'] = pd.to_datetime(curdf.Date)\n",
    "        # Set date as index\n",
    "        curdf = curdf.set_index('Date')\n",
    "        \n",
    "        # Prepare dataframe to save to file\n",
    "        dfToSave = curdf.copy()\n",
    "\n",
    "        for ageIndex in range(len(ageGroups)):\n",
    "            # Get current agegroups and name\n",
    "            curAgeGroup = ageGroups[ageIndex]\n",
    "            curAgeName = ageGroupNames[ageIndex]\n",
    "\n",
    "            # Update progressbar\n",
    "            pbar.set_postfix(\n",
    "                {\n",
    "                    'Amt':curAmtName,\n",
    "                    'Period':i+1,\n",
    "                    'Total periods':len(allStarts),\n",
    "                    'Start':curStart,\n",
    "                    'End':curEnd,\n",
    "                    'Agegroup':curAgeName,\n",
    "                }\n",
    "            )\n",
    "            \n",
    "\n",
    "            # Sum the columns of the given agegroups\n",
    "            curSeries = sumColumns(curdf,curAgeGroup)\n",
    "\n",
    "            # Calculate the 7-day average to avoid trouble with Sundays having more burials than other weekdays\n",
    "            curSeriesRn = curSeries.rolling(window=7,center=True).mean()\n",
    "\n",
    "            # this_curTime,this_curVals,this_corrMean,this_corrStd,this_postResi,this_postResiStd,this_postResiPct = emf.runFullAnalysisDailySeries(curSeriesRn,numYears=numYears,ZscoreThreshold=thresholdExcess)\n",
    "            # curBaseline,curStandardDeviation,curExcess,curZscore,curExcessPct\n",
    "            curBaseline,curStandardDeviation,curExcess,curZscore,curExcessPct = emf.runFullAnalysisDailySeries(curSeriesRn,numYears=numYears,ZscoreThreshold=thresholdExcess)\n",
    "            \n",
    "            # Make a dataframe for results\n",
    "            dfResults = pd.DataFrame(\n",
    "                {\n",
    "                    # curAgeName+'_Data':curSeries,\n",
    "                    curAgeName+'_Data7DayMean':curSeriesRn,\n",
    "                    curAgeName+'_Baseline':curBaseline, \n",
    "                    curAgeName+'_StandardDeviation':curStandardDeviation,\n",
    "                    curAgeName+'_Zscore':curZscore, \n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Merge with data and results-so-far\n",
    "            dfToSave = pd.merge(dfToSave,dfResults, left_index=True, right_index=True)\n",
    "    \n",
    "        # Determine filename to save file as\n",
    "        curFileName =  str(int(curAmtID)) + '_'+curAmtName + '_'+pd.to_datetime(curStart).strftime('%Y-%m-%d') +'_'+pd.to_datetime(curEnd).strftime('%Y-%m-%d')\n",
    "        # curFileName = curFileName + '_'+curAgeName+'.csv'\n",
    "        curFileName = curFileName + '.csv'\n",
    "        \n",
    "        # # Save county results to file\n",
    "        # dfToSave.reset_index().to_csv('test.csv')\n",
    "        # Only save analysis results, to save space in github repo\n",
    "        dfToSave.iloc[:,curdf.shape[1]:].reset_index().to_csv(pathToSaveResultsInUpper + curFileName,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old version, saved age-specific results in separate directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################\n",
    "# ##### Run analysis for each of the agegroups #####\n",
    "# ############ Takes about half an hour ############ \n",
    "# ##################################################\n",
    "\n",
    "# for ageIndex in range(len(ageGroups)):\n",
    "#     # Get current agegroups and name\n",
    "#     curAgeGroup = ageGroups[ageIndex]\n",
    "#     curAgeName = ageGroupNames[ageIndex]\n",
    "\n",
    "#     # Determine path to save results in \n",
    "#     pathToSaveResultsInLower = pathToSaveResultsInUpper + '/Age_' + curAgeName+'/'\n",
    "\n",
    "#     # Create subdirectory\n",
    "#     try:\n",
    "#         os.mkdir(pathToSaveResultsInLower)\n",
    "#     except:\n",
    "#         2+2\n",
    "\n",
    "#     # Prepare progressbar and go through each county\n",
    "#     pbar = tqdm(allAmtIDs)\n",
    "#     for curAmtID in pbar:\n",
    "\n",
    "#         # Get county name, data and periods\n",
    "#         curAmtName = ps.getAmtName(curAmtID)\n",
    "#         alldfs,allStarts,allEnds = ps.getAmtCollections(curAmtID)\n",
    "\n",
    "#         # Go through each possible period\n",
    "#         for i in range(len(allStarts)):\n",
    "\n",
    "#             # Get the dataframe, start date and end date\n",
    "#             curdf = alldfs[i].copy()\n",
    "#             curStart = allStarts[i]\n",
    "#             curEnd = allEnds[i]\n",
    "\n",
    "#             # Update progressbar\n",
    "#             pbar.set_postfix(\n",
    "#                 {\n",
    "#                     'Agegroup':curAgeName,\n",
    "#                     'Amt':curAmtName,\n",
    "#                     'Period':i,\n",
    "#                     'Total periods':len(allStarts),\n",
    "#                     'Start':curStart,\n",
    "#                     'End':curEnd,\n",
    "#                 }\n",
    "#             )\n",
    "            \n",
    "#             # Ensure date is datetime\n",
    "#             curdf['Date'] = pd.to_datetime(curdf.Date)\n",
    "#             # Set date as index\n",
    "#             curdf = curdf.set_index('Date')\n",
    "\n",
    "#             # Sum the columns of the given agegroups\n",
    "#             curSeries = sumColumns(curdf,curAgeGroup)\n",
    "\n",
    "#             # Calculate the 7-day average to avoid trouble with Sundays having more burials than other weekdays\n",
    "#             curSeriesRn = curSeries.rolling(window=7,center=True).mean()\n",
    "\n",
    "#             # this_curTime,this_curVals,this_corrMean,this_corrStd,this_postResi,this_postResiStd,this_postResiPct = emf.runFullAnalysisDailySeries(curSeriesRn,numYears=numYears,ZscoreThreshold=thresholdExcess)\n",
    "#             # curBaseline,curStandardDeviation,curExcess,curZscore,curExcessPct\n",
    "#             curBaseline,curStandardDeviation,curExcess,curZscore,curExcessPct = emf.runFullAnalysisDailySeries(curSeriesRn,numYears=numYears,ZscoreThreshold=thresholdExcess)\n",
    "            \n",
    "            \n",
    "#             # Make a dataframe for results\n",
    "#             dfResults = pd.DataFrame(\n",
    "#                 {\n",
    "#                     'Data':curSeries,\n",
    "#                     'DataSmooth':curSeriesRn,\n",
    "#                     'Baseline':curBaseline, \n",
    "#                     'StandardDeviation':curStandardDeviation,\n",
    "#                     'Zscore':curZscore, \n",
    "#                 }\n",
    "#             )\n",
    "\n",
    "\n",
    "#             # Determine filename to save file as\n",
    "#             curFileName =  str(int(curAmtID)) + '_'+curAmtName + '_'+pd.to_datetime(curStart).strftime('%Y-%m-%d') +'_'+pd.to_datetime(curEnd).strftime('%Y-%m-%d')\n",
    "#             curFileName = curFileName + '_'+curAgeName+'.csv'\n",
    "\n",
    "#             # Save to file (reset index to also save date to file)\n",
    "#             dfResults.reset_index().to_csv(pathToSaveResultsInLower+curFileName,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1231565b209786dac476dcddb6c851658cee15112262a0f5b5be5fa490b6ca1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
