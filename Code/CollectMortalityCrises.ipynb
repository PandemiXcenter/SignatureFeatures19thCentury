{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine mortality crises\n",
    "\n",
    "This notebook takes the results generated in \"AnalyzeExcessMortality.ipynb\" and identifies extended periods with excess mortality and groups them together as \"mortality crises\". \n",
    "\n",
    "The results are collected in a single dataframe, which is saved as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading packages\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "# Load style\n",
    "plt.style.use('PlotStyle.mplstyle')\n",
    "import matplotlib.colors as colors\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.Dark2.colors)\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "# Load functions\n",
    "import sys\n",
    "sys.path.append(\"../../ExcessMortality\")\n",
    "import ExcessMortalityFunctions as emf\n",
    "import AdditionalFunctions as ps\n",
    "\n",
    "\n",
    "# saveFigures = True\n",
    "# # saveFigures = False\n",
    "# print('saveFigures is set to: '+str(saveFigures))\n",
    "print('Done loading packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "pathData = '../Data/'\n",
    "# pathResults = '../../AnalysisResults' # NOTE: Outside repo! This is done to save space within repo. In the final part of the analysis, everything is put together in a single file\n",
    "pathResults = '../Data/AnalysisResults' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRel = pd.read_csv('../SupplementaryTable_RelationalTable_ParishCounty.csv')\n",
    "dfRel['StartDate'] = pd.to_datetime(dfRel.StartDate)\n",
    "dfRel['EndDate'] = pd.to_datetime(dfRel.EndDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table with population data\n",
    "dfPop = pd.read_excel(pathData + 'AmtPopulation.xlsx')\n",
    "dfPop['DigDagID'] = dfPop['DigDagID'].fillna(0).astype(int) # Since excel sometimes saves ints as floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# Only consider counties that exists after 1810 \n",
    "# (A large restructuring was done between 1800 and 1810)\n",
    "# print(dfRel.AmtID.unique())\n",
    "print(len(dfRel.AmtID.unique()))\n",
    "allAmtIDs = dfRel[dfRel.EndDate > np.datetime64('1810-01-01')].AmtID.unique()\n",
    "# print(allAmtIDs)\n",
    "print(len(allAmtIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters used in main analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags and analysis parameters used in main analysis \n",
    "numYears = 6 # Number of years on both sides of date to use for baseline calculations \n",
    "numYears = 12 # Number of years on both sides of date to use for baseline calculations \n",
    "numYearsTot = (numYears*2) # The \"name\" of the baseline (i.e. +/- 5 years is a 10-year baseline, +/- 12 is a 24 year baseline)\n",
    "thresholdExcess = 3 # Threshold (in terms of Z-scores) for identifying a day as having increased excess\n",
    "\n",
    "# Determine directory in which results was saved\n",
    "pathResultsUpper = pathResults + f'_Years{numYears}_Threshold{thresholdExcess}/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agegroups analyzed\n",
    "ageGroups = [\n",
    "    ['Total'],\n",
    "    ['Stillborn','0'],\n",
    "    ['1-4','5-9', '10-14'],\n",
    "    ['15-19', '20-24', '25-29', '30-34', '35-39'],\n",
    "    ['40-44', '45-49', '50-54', '55-59'],\n",
    "    ['60-64', '65-69', '70-74', '75-79', '80+']\n",
    "]\n",
    "\n",
    "# And the names used for directories and filenames\n",
    "ageGroupNames = [\n",
    "    'Total',\n",
    "    'Infants_stillborn',\n",
    "    '1-14',\n",
    "    '15-39',\n",
    "    '40-59',\n",
    "    '60+'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for identification of mortality crises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AllCrises_Years12_Threshold3_LowerThreshold2_MaxDaysBelow4_minLength4_minCount20'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters to use here\n",
    "thresholdLower = 2 # Lower threshold used for determining the start and end of periods (in terms of Z-scores)\n",
    "maxDaysBelowThreshold = 4 # Number of days below thresholdLower before a period of excess is \"stopped\"\n",
    "# maxDaysBelowThreshold = 7 # Number of days below thresholdLower before a period of excess is \"stopped\"\n",
    "minimumLengthOfEpidemic = 4 # Minimal number of days above thresholdExcess which is counted as a period of excess \n",
    "\n",
    "excessCountThreshold = 50 # Only save mortality crises with more than this number of excess deaths\n",
    "excessCountThreshold = 20 # Only save mortality crises with more than this number of excess deaths\n",
    "\n",
    "# Determine filename to use for final results\n",
    "finalResultsFilename = 'AllCrises'+f'_Years{numYears}_Threshold{thresholdExcess}_LowerThreshold{thresholdLower}_MaxDaysBelow{maxDaysBelowThreshold}_minLength{minimumLengthOfEpidemic}_minCount{excessCountThreshold}'\n",
    "finalResultsFilename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for saving season and quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeason(d):\n",
    "    curMonth = pd.to_datetime(d).month\n",
    "    \n",
    "    seasonDict = {\n",
    "        1:'Winter',\n",
    "        2:'Winter',\n",
    "        3:'Spring',\n",
    "        4:'Spring',\n",
    "        5:'Spring',\n",
    "        6:'Summer',\n",
    "        7:'Summer',\n",
    "        8:'Summer',\n",
    "        9:'Fall',\n",
    "        10:'Fall',\n",
    "        11:'Fall',\n",
    "        12:'Winter',\n",
    "    }\n",
    "    return seasonDict[curMonth]\n",
    "    \n",
    "def getQuarter(d):\n",
    "    curMonth = pd.to_datetime(d).month\n",
    "    \n",
    "    QuarterDict = {\n",
    "        1:'Q1',\n",
    "        2:'Q1',\n",
    "        3:'Q1',\n",
    "        4:'Q2',\n",
    "        5:'Q2',\n",
    "        6:'Q2',\n",
    "        7:'Q3',\n",
    "        8:'Q3',\n",
    "        9:'Q3',\n",
    "        10:'Q4',\n",
    "        11:'Q4',\n",
    "        12:'Q4',\n",
    "    }\n",
    "    return QuarterDict[curMonth]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for interpolation of population counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPopRow(amtID):\n",
    "    curRow = dfPop[dfPop.DigDagID == amtID]\n",
    "    if len(curRow) == 0:\n",
    "        print(amtID)\n",
    "        print('----- Amt not found in population table -----')\n",
    "\n",
    "    elif len(curRow) > 1:\n",
    "        # print(f'----- Amt ID {amtID} gives too many results -----')        \n",
    "        return curRow\n",
    "    else:\n",
    "        return curRow \n",
    "\n",
    "def AmtIDToDailyPopulation(amtID,dateToFocusOn=np.datetime64('1870-01-01')):\n",
    "    \n",
    "    # Get current row from population table\n",
    "    curPopRow = getPopRow(amtID)\n",
    "    # Remove name and ID\n",
    "    curPopRow = curPopRow.iloc[:,2:]\n",
    "\n",
    "    # Special case for Århus Amt (for deciding whether to include Skanderborg Amt counts or not)\n",
    "    if (amtID == 118846):\n",
    "        if dateToFocusOn >= np.datetime64('1867-01-01'):\n",
    "            curPopRow = curPopRow.iloc[1:]\n",
    "        else:\n",
    "            curPopRow = curPopRow.iloc[:1]\n",
    "            \n",
    "    # Transpose and rename\n",
    "    curdfPop = curPopRow.T.reset_index()\n",
    "    curdfPop = curdfPop.rename(columns={curdfPop.columns[0]:'Year',curdfPop.columns[1]:'Population'})\n",
    "\n",
    "    # Get years-values as dates        \n",
    "    curdfPop['Date'] = [np.datetime64(str(x)+'-01-01') for x in curdfPop.Year]\n",
    "\n",
    "    # Make a dataframe with all dates\n",
    "    dfAllDates = pd.DataFrame(\n",
    "        {'Date':np.arange(curdfPop.Date.iloc[0],curdfPop.Date.iloc[-1],np.timedelta64(1,'D'))}\n",
    "    ) \n",
    "\n",
    "    # Merge with empty\n",
    "    curdfPop = pd.merge(curdfPop,dfAllDates,on='Date',how='outer').sort_values('Date').drop(columns='Year')\n",
    "\n",
    "    ## New addition during review: Exponential interpolation rather than linear\n",
    "    # Log population counts before interpolation\n",
    "    curdfPop['Population'] = np.log(curdfPop['Population'])\n",
    "\n",
    "    # Carry out interpolation\n",
    "    curdfPopInterpolate = curdfPop.set_index('Date').interpolate()\n",
    "\n",
    "    ## New addition during review: Exponential interpolation rather than linear\n",
    "    # Take exponential of interpolated number \n",
    "    curdfPopInterpolate['Population'] = np.exp(curdfPopInterpolate['Population'])\n",
    "    curdfPop['Population'] = np.exp(curdfPop['Population'])\n",
    "    \n",
    "    return curdfPop,curdfPopInterpolate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run through all saved files, identify crises and collect them in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataframe to collect results in \n",
    "# dfCrisesCollect = pd.DataFrame(\n",
    "#     columns = [\n",
    "#         'Amt',\n",
    "#         'Start',\n",
    "#         'End',\n",
    "#         'NumberOfDays',\n",
    "#         'DayWithMostBurials',\n",
    "#         'Excess',\n",
    "#         'ExcessPct',\n",
    "#         'GenderRatio',\n",
    "#         'TimeOfYear',\n",
    "#         'Season'\n",
    "#     ]\n",
    "# ) \n",
    "\n",
    "dfCrisesCollectAge = pd.DataFrame(\n",
    "    columns = [\n",
    "        'Amt',\n",
    "        'Start',\n",
    "        'End',\n",
    "        'NumberOfDays',\n",
    "        'DayWithMostBurials',\n",
    "        'Excess',\n",
    "        'ExcessPct',\n",
    "        'GenderRatio',\n",
    "        'TimeOfYear',\n",
    "        'Season',\n",
    "        'PopulationEstimate',\n",
    "        'Exc_Infants_stillborn',\n",
    "        'Exc_1-14',\n",
    "        'Exc_15-39',\n",
    "        'Exc_40-59',\n",
    "        'Exc_60+',\n",
    "        'Pct_Infants_stillborn',\n",
    "        'Pct_1-14',\n",
    "        'Pct_15-39',\n",
    "        'Pct_40-59',\n",
    "        'Pct_60+',\n",
    "        'DataSum_Infants_stillborn',\n",
    "        'DataSum_1-14',\n",
    "        'DataSum_15-39',\n",
    "        'DataSum_40-59',\n",
    "        'DataSum_60+',\n",
    "        'Baseline_Infants_stillborn',\n",
    "        'Baseline_1-14',\n",
    "        'Baseline_15-39',\n",
    "        'Baseline_40-59',\n",
    "        'Baseline_60+',\n",
    "    ]\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [01:23<00:00,  3.10s/it, Amt=Nordborg Amt, Period=1, Total periods=2, Start=1867-09-22, End=1915-01-01]     \n"
     ]
    }
   ],
   "source": [
    "# Prepare progressbar and go through all counties\n",
    "pbar = tqdm(allAmtIDs)\n",
    "for curAmtID in pbar:\n",
    "\n",
    "    # Get county name, data and periods\n",
    "    curAmtName = ps.getAmtName(curAmtID)\n",
    "    alldfs,allStarts,allEnds = ps.getAmtCollections(curAmtID)\n",
    "\n",
    "\n",
    "    # Go through each possible period\n",
    "    for i in range(len(allStarts)):\n",
    "\n",
    "        # Get the dataframe, start date and end date\n",
    "        curdf = alldfs[i].copy()\n",
    "        curStart = allStarts[i]\n",
    "        curEnd = allEnds[i]\n",
    "\n",
    "        # Make sure that the \"Date\" columns in the data-dataframe is a datetime64 object\n",
    "        curdf['Date'] = pd.to_datetime(curdf['Date'])\n",
    "\n",
    "        # Update progressbar\n",
    "        pbar.set_postfix(\n",
    "            {\n",
    "                'Amt':curAmtName,\n",
    "                'Period':i,\n",
    "                'Total periods':len(allStarts),\n",
    "                'Start':curStart,\n",
    "                'End':curEnd,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Determine filename results-file\n",
    "        curFileName =  str(int(curAmtID)) + '_'+curAmtName + '_'+pd.to_datetime(curStart).strftime('%Y-%m-%d') +'_'+pd.to_datetime(curEnd).strftime('%Y-%m-%d')\n",
    "        # curFileName = curFileName + '_Total.csv' # Use results from analysis of all ages\n",
    "        curFileName = curFileName + '.csv' \n",
    "\n",
    "        # Load analysis file\n",
    "        dfPeriod = pd.read_csv(pathResultsUpper+curFileName)\n",
    "        # Make sure date is a datetime64 object\n",
    "        dfPeriod['Date'] = pd.to_datetime(dfPeriod.Date)\n",
    "\n",
    "        # Restrict to valid period \n",
    "        dfPeriod = dfPeriod[(dfPeriod.Date >= curStart) & (dfPeriod.Date < curEnd)].reset_index(drop=True)\n",
    "\n",
    "        # Get results and re-calculate excess\n",
    "        curTime = dfPeriod.Date \n",
    "        curExcess = dfPeriod.Total_Data7DayMean - dfPeriod.Total_Baseline \n",
    "        curZscore = dfPeriod.Total_Zscore \n",
    "        \n",
    "        # Use function from ExcessMortalityFunctions to determine mortality crisis period\n",
    "        dateGroups,allExcess  = emf.determineMortalityCrisis(curTime,curExcess,curZscore,upperThreshold=thresholdExcess,lowerThreshold=thresholdLower,maxDaysBelowThreshold=maxDaysBelowThreshold,minimumLengthOfEpidemic=minimumLengthOfEpidemic,returnExcessCount=True)\n",
    "        \n",
    "        # Go through each mortality crisis\n",
    "        for excID in range(len(dateGroups)):\n",
    "            \n",
    "            # Get current start, end and total excess\n",
    "            curGroup = dateGroups[excID]\n",
    "            curExc = allExcess[excID]\n",
    "\n",
    "            # If the period is significant enough\n",
    "            if (curExc >= excessCountThreshold):\n",
    "                \n",
    "                # Get start and end\n",
    "                curCrisisStart = curGroup[0]\n",
    "                curCrisisEnd = curGroup[1]\n",
    "\n",
    "                # Determine duraction (in days)\n",
    "                curDuration = int((curCrisisEnd - curCrisisStart)/np.timedelta64(1,'D'))\n",
    "\n",
    "                # Calculate gender ratio of all deaths in period from data-collection dataframe\n",
    "                dfDataCrisis = curdf[(curdf.Date >= curCrisisStart) & (curdf.Date <= curCrisisEnd)]\n",
    "                GenderRatioInPeriod = dfDataCrisis.Male.sum()/(dfDataCrisis.Male.sum()+dfDataCrisis.Female.sum())\n",
    "\n",
    "                # Determine the date (during the crisis) where raw data is highest.\n",
    "                curDeadliestDay = dfDataCrisis.iloc[dfDataCrisis.Total.argmax()]['Date']\n",
    "                \n",
    "                # Make a dataframe consisting of analysis-results only during period\n",
    "                dfCrisis = dfPeriod[(dfPeriod.Date >= curCrisisStart) & (dfPeriod.Date <= curCrisisEnd)]\n",
    "\n",
    "                # Total deaths in period, data\n",
    "                curTotData = dfCrisis.Total_Data7DayMean.sum()\n",
    "                # Total deaths in period, baseline\n",
    "                curTotBase = dfCrisis.Total_Baseline.sum()\n",
    "                # Excess deaths in entire period, in percent\n",
    "                curExcPct = (curTotData - curTotBase)/curTotBase\n",
    "                # curExcPct = int(np.round(100 * curExcPct))\n",
    "                curExcPct = np.round(100 * curExcPct)\n",
    "\n",
    "                # Get population estimate (rounded to an integer)\n",
    "                _,populationInterpolated = AmtIDToDailyPopulation(curAmtID,curDeadliestDay)\n",
    "                curPopulation = np.round(populationInterpolated.loc[curDeadliestDay]['Population'])\n",
    "\n",
    "                # Collect results as a row to add to dataframe\n",
    "                curRowToAdd = pd.Series({\n",
    "                    'Amt': curAmtName,\n",
    "                    'Start': curCrisisStart,\n",
    "                    'End': curCrisisEnd,\n",
    "                    'NumberOfDays': curDuration,\n",
    "                    'DayWithMostBurials': curDeadliestDay,\n",
    "                    'Excess': int(np.round(curExc)),\n",
    "                    'ExcessPct': curExcPct,\n",
    "                    'GenderRatio': GenderRatioInPeriod,\n",
    "                    'TimeOfYear': getQuarter(curDeadliestDay),\n",
    "                    'Season': getSeason(curDeadliestDay),\n",
    "                    'PopulationEstimate': curPopulation,\n",
    "                })\n",
    "\n",
    "                # # Add row to primary dataframe\n",
    "                # dfCrisesCollect.loc[len(dfCrisesCollect)] = curRowToAdd\n",
    "            \n",
    "                #### Get results of age-specific analysis\n",
    "                # Go through each agegroup\n",
    "                for ageIndex in range(len(ageGroups)):\n",
    "                    \n",
    "                    # Get the agegroup and the name of the group\n",
    "                    curAgeGroup = ageGroups[ageIndex]\n",
    "                    curAgeName = ageGroupNames[ageIndex]\n",
    "\n",
    "                    # Calculate age-specific measures in excess-mortality-period\n",
    "                    curTotDataAge = dfCrisis[curAgeName+'_Data7DayMean'].sum()\n",
    "                    curTotBaseAge = dfCrisis[curAgeName+'_Baseline'].sum()\n",
    "\n",
    "                    curExcAge = curTotDataAge - curTotBaseAge\n",
    "                    curExcPctAge = (curExcAge)/curTotBaseAge\n",
    "                    # curExcPctAge = int(np.round(100 * curExcPctAge))\n",
    "                    curExcPctAge = np.round(100 * curExcPctAge)\n",
    "\n",
    "\n",
    "                    curRowToAdd['Exc_'+curAgeName] = curExcAge\n",
    "                    curRowToAdd['Pct_'+curAgeName] = curExcPctAge\n",
    "                    curRowToAdd['DataSum_'+curAgeName] = curTotDataAge\n",
    "                    curRowToAdd['Baseline_'+curAgeName] = curTotBaseAge\n",
    "                    \n",
    "                # Add row to primary dataframe\n",
    "                dfCrisesCollectAge.loc[len(dfCrisesCollectAge)] = curRowToAdd\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove crises in earliest period of data, since data is not realiable in this period\n",
    "# dfCrisesCollect = dfCrisesCollect.drop(dfCrisesCollect[dfCrisesCollect.End < np.datetime64('1820-01-01')].index)\n",
    "dfCrisesCollectAge = dfCrisesCollectAge.drop(dfCrisesCollectAge[dfCrisesCollectAge.End < np.datetime64('1820-01-01')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort by total excess\n",
    "# dfCrisesCollect = dfCrisesCollect.sort_values('Excess',ascending=False)\n",
    "dfCrisesCollectAge = dfCrisesCollectAge.sort_values('Excess',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save results\n",
    "# dfCrisesCollect.to_csv(pathResultsUpper + 'AllCrises_noAge_preClustering.csv')\n",
    "# dfCrisesCollectAge.to_csv(pathResultsUpper + 'AllCrises_preClustering.csv')\n",
    "dfCrisesCollectAge.to_csv(pathData + finalResultsFilename+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save file as excel (with dates as strings to avoid excel-problems)\n",
    "dfCrisesCollectAgeExcel = dfCrisesCollectAge.copy()\n",
    "dfCrisesCollectAgeExcel['Start'] = dfCrisesCollectAgeExcel['Start'].astype(str)\n",
    "dfCrisesCollectAgeExcel['End'] = dfCrisesCollectAgeExcel['End'].astype(str)\n",
    "dfCrisesCollectAgeExcel['DayWithMostBurials'] = dfCrisesCollectAgeExcel['DayWithMostBurials'].astype(str)\n",
    "\n",
    "dfCrisesCollectAgeExcel.to_excel(pathData + finalResultsFilename+'.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old version based on separate directories for each age-group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfCrisesCollectAge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare progressbar and go through all counties\n",
    "# pbar = tqdm(allAmtIDs)\n",
    "# for curAmtID in pbar:\n",
    "\n",
    "#     # Get county name, data and periods\n",
    "#     curAmtName = ps.getAmtName(curAmtID)\n",
    "#     alldfs,allStarts,allEnds = ps.getAmtCollections(curAmtID)\n",
    "\n",
    "\n",
    "#     # Go through each possible period\n",
    "#     for i in range(len(allStarts)):\n",
    "\n",
    "#         # Get the dataframe, start date and end date\n",
    "#         curdf = alldfs[i].copy()\n",
    "#         curStart = allStarts[i]\n",
    "#         curEnd = allEnds[i]\n",
    "\n",
    "#         # Make sure that the \"Date\" columns in the data-dataframe is a datetime64 object\n",
    "#         curdf['Date'] = pd.to_datetime(curdf['Date'])\n",
    "\n",
    "#         # Update progressbar\n",
    "#         pbar.set_postfix(\n",
    "#             {\n",
    "#                 'Amt':curAmtName,\n",
    "#                 'Period':i,\n",
    "#                 'Total periods':len(allStarts),\n",
    "#                 'Start':curStart,\n",
    "#                 'End':curEnd,\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         # Determine filename results-file\n",
    "#         curFileName =  str(int(curAmtID)) + '_'+curAmtName + '_'+pd.to_datetime(curStart).strftime('%Y-%m-%d') +'_'+pd.to_datetime(curEnd).strftime('%Y-%m-%d')\n",
    "#         curFileName = curFileName + '_Total.csv' # Use results from analysis of all ages\n",
    "\n",
    "#         # Load analysis file\n",
    "#         dfPeriod = pd.read_csv(pathResultsUpper+'Age_Total/'+curFileName)\n",
    "#         # Make sure date is a datetime64 object\n",
    "#         dfPeriod['Date'] = pd.to_datetime(dfPeriod.Date)\n",
    "\n",
    "#         # Restrict to valid period \n",
    "#         dfPeriod = dfPeriod[(dfPeriod.Date >= curStart) & (dfPeriod.Date < curEnd)].reset_index(drop=True)\n",
    "\n",
    "#         # Get results and re-calculate excess\n",
    "#         curTime = dfPeriod.Date \n",
    "#         curExcess = dfPeriod.DataSmooth - dfPeriod.Baseline \n",
    "#         curZscore = dfPeriod.Zscore \n",
    "        \n",
    "#         # Use function from ExcessMortalityFunctions to determine mortality crisis period\n",
    "#         dateGroups,allExcess  = emf.determineMortalityCrisis(curTime,curExcess,curZscore,upperThreshold=thresholdExcess,lowerThreshold=thresholdLower,maxDaysBelowThreshold=maxDaysBelowThreshold,minimumLengthOfEpidemic=minimumLengthOfEpidemic,returnExcessCount=True)\n",
    "        \n",
    "#         # Go through each mortality crisis\n",
    "#         for excID in range(len(dateGroups)):\n",
    "            \n",
    "#             # Get current start, end and total excess\n",
    "#             curGroup = dateGroups[excID]\n",
    "#             curExc = allExcess[excID]\n",
    "\n",
    "#             # If the period is significant enough\n",
    "#             if (curExc >= excessCountThreshold):\n",
    "                \n",
    "#                 # Get start and end\n",
    "#                 curCrisisStart = curGroup[0]\n",
    "#                 curCrisisEnd = curGroup[1]\n",
    "\n",
    "#                 # Calculate gender ratio of all deaths in period from data-collection dataframe\n",
    "#                 dfDataCrisis = curdf[(curdf.Date >= curCrisisStart) & (curdf.Date <= curCrisisEnd)]\n",
    "#                 GenderRatioInPeriod = dfDataCrisis.Male.sum()/(dfDataCrisis.Male.sum()+dfDataCrisis.Female.sum())\n",
    "                \n",
    "#                 # Determine duraction (in days)\n",
    "#                 curDuration = int((curCrisisEnd - curCrisisStart)/np.timedelta64(1,'D'))\n",
    "\n",
    "#                 # Make a dataframe consisting of analysis-results only during period\n",
    "#                 dfCrisis = dfPeriod[(dfPeriod.Date >= curCrisisStart) & (dfPeriod.Date <= curCrisisEnd)]\n",
    "\n",
    "#                 # Determine the date (during the crisis) where raw data is highest.\n",
    "#                 curDeadliestDay = dfCrisis.iloc[dfCrisis.Data.argmax()]['Date']\n",
    "\n",
    "#                 # Total deaths in period, data\n",
    "#                 curTotData = dfCrisis.DataSmooth.sum()\n",
    "#                 # Total deaths in period, baseline\n",
    "#                 curTotBase = dfCrisis.Baseline.sum()\n",
    "#                 # Excess deaths in entire period, in percent\n",
    "#                 curExcPct = (curTotData - curTotBase)/curTotBase\n",
    "#                 curExcPct = int(np.round(100 * curExcPct))\n",
    "\n",
    "#                 # Get population estimate (rounded to an integer)\n",
    "#                 _,populationInterpolated = AmtIDToDailyPopulation(curAmtID,curDeadliestDay)\n",
    "#                 curPopulation = np.round(populationInterpolated.loc[curDeadliestDay]['Population'])\n",
    "\n",
    "#                 # Collect results as a row to add to dataframe\n",
    "#                 curRowToAdd = pd.Series({\n",
    "#                     'Amt': curAmtName,\n",
    "#                     'Start': curCrisisStart,\n",
    "#                     'End': curCrisisEnd,\n",
    "#                     'NumberOfDays': curDuration,\n",
    "#                     'DayWithMostBurials': curDeadliestDay,\n",
    "#                     'Excess': int(np.round(curExc)),\n",
    "#                     'ExcessPct': curExcPct,\n",
    "#                     'GenderRatio': GenderRatioInPeriod,\n",
    "#                     'TimeOfYear': getQuarter(curDeadliestDay),\n",
    "#                     'Season': getSeason(curDeadliestDay),\n",
    "#                     'PopulationEstimate': curPopulation,\n",
    "#                 })\n",
    "\n",
    "#                 # # Add row to primary dataframe\n",
    "#                 # dfCrisesCollect.loc[len(dfCrisesCollect)] = curRowToAdd\n",
    "            \n",
    "\n",
    "#                 #### Get results of age-specific analysis\n",
    "#                 # Go through each agegroup\n",
    "#                 for ageIndex in range(len(ageGroups)):\n",
    "                    \n",
    "#                     # Get the agegroup and the name of the group\n",
    "#                     curAgeGroup = ageGroups[ageIndex]\n",
    "#                     curAgeName = ageGroupNames[ageIndex]\n",
    "\n",
    "#                     # Get the filename to load\n",
    "#                     curFileName =  str(int(curAmtID)) + '_'+curAmtName + '_'+pd.to_datetime(curStart).strftime('%Y-%m-%d') +'_'+pd.to_datetime(curEnd).strftime('%Y-%m-%d')\n",
    "#                     curFileName = curFileName + '_'+curAgeName+'.csv'\n",
    "\n",
    "#                     # Load file\n",
    "#                     dfPeriodAge = pd.read_csv(pathResultsUpper+'/Age_'+curAgeName+'/'+curFileName)\n",
    "#                     # Convert to datetime\n",
    "#                     dfPeriodAge['Date'] = pd.to_datetime(dfPeriodAge.Date)\n",
    "                        \n",
    "#                     # Calculate age-specific measures in excess-mortality-period\n",
    "#                     dfCrisisAge = dfPeriodAge[(dfPeriodAge.Date >= curCrisisStart) & (dfPeriodAge.Date <= curCrisisEnd)]\n",
    "#                     curTotDataAge = dfCrisisAge.DataSmooth.sum()\n",
    "#                     curTotBaseAge = dfCrisisAge.Baseline.sum()\n",
    "#                     curExcAge = curTotDataAge - curTotBaseAge\n",
    "#                     curExcPctAge = (curExcAge)/curTotBaseAge\n",
    "#                     curExcPctAge = int(np.round(100 * curExcPctAge))\n",
    "\n",
    "\n",
    "#                     curRowToAdd['Exc_'+curAgeName] = curExcAge\n",
    "#                     curRowToAdd['Pct_'+curAgeName] = curExcPctAge\n",
    "#                     curRowToAdd['Total_'+curAgeName] = curTotDataAge\n",
    "#                     curRowToAdd['Baseline_'+curAgeName] = curTotBaseAge\n",
    "                    \n",
    "#                 # Add row to primary dataframe\n",
    "#                 dfCrisesCollectAge.loc[len(dfCrisesCollectAge)] = curRowToAdd\n",
    "                                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1231565b209786dac476dcddb6c851658cee15112262a0f5b5be5fa490b6ca1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
